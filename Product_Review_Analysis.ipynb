{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDwNKt4o6MSP",
        "outputId": "76ea8882-93ae-4249-eb2d-20ca067aac62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5000 entries, 0 to 4999\n",
            "Data columns (total 24 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   id                   5000 non-null   object \n",
            " 1   dateAdded            5000 non-null   object \n",
            " 2   dateUpdated          5000 non-null   object \n",
            " 3   name                 5000 non-null   object \n",
            " 4   asins                5000 non-null   object \n",
            " 5   brand                5000 non-null   object \n",
            " 6   categories           5000 non-null   object \n",
            " 7   primaryCategories    5000 non-null   object \n",
            " 8   imageURLs            5000 non-null   object \n",
            " 9   keys                 5000 non-null   object \n",
            " 10  manufacturer         5000 non-null   object \n",
            " 11  manufacturerNumber   5000 non-null   object \n",
            " 12  reviews.date         5000 non-null   object \n",
            " 13  reviews.dateAdded    1052 non-null   object \n",
            " 14  reviews.dateSeen     5000 non-null   object \n",
            " 15  reviews.doRecommend  5000 non-null   bool   \n",
            " 16  reviews.id           29 non-null     float64\n",
            " 17  reviews.numHelpful   5000 non-null   int64  \n",
            " 18  reviews.rating       5000 non-null   int64  \n",
            " 19  reviews.sourceURLs   5000 non-null   object \n",
            " 20  reviews.text         5000 non-null   object \n",
            " 21  reviews.title        4987 non-null   object \n",
            " 22  reviews.username     4999 non-null   object \n",
            " 23  sourceURLs           5000 non-null   object \n",
            "dtypes: bool(1), float64(1), int64(2), object(20)\n",
            "memory usage: 903.4+ KB\n",
            "(5000, 24)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/Datafiniti_Amazon_Consumer_Reviews_of_Amazon_Products.csv')\n",
        "\n",
        "df.info()\n",
        "\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[['reviews.text', 'reviews.rating']]\n",
        "df = df.dropna()\n",
        "df = df [df['reviews.rating']!= '']\n",
        "df['reviews.rating'] = df['reviews.rating'].astype(float)\n"
      ],
      "metadata": {
        "id": "RHPCw2oE-7Lw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment(rating):\n",
        "  if rating >= 4.0:\n",
        "    return \"positive\"\n",
        "\n",
        "  elif rating == 3.0:\n",
        "    return \"neutral\"\n",
        "  else:\n",
        "    return \"negative\"\n",
        "\n",
        "df['sentiment'] = df['reviews.rating'].apply(get_sentiment)"
      ],
      "metadata": {
        "id": "S3irNldPBD6V"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re, nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "  text = text.lower()\n",
        "  text = re.sub(r\"http\\S+|\\W+\", \"\", text)\n",
        "  tokens = nltk.word_tokenize(text)\n",
        "  tokens = [lemmatizer.lemmatize(w) for w in tokens if w not in stop and len(w)>2]\n",
        "  return \" \".join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXSjASZNB15o",
        "outputId": "b92362d5-7af6-4dce-97c0-3b556b810f93"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df['clean'] = df['reviews.text'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "5j7mRs_ZDuoy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "tfidf = TfidfVectorizer(max_features=10000)\n",
        "X = tfidf.fit_transform(df['clean'])\n",
        "y = df['sentiment']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "os.makedirs(\"app\", exist_ok= True)\n",
        "joblib.dump(model, \"app/model.pkl\")\n",
        "joblib.dump(tfidf, \"app/vectorizer.pkl\")\n",
        "\n",
        "df_test = df_test.copy()\n",
        "df_test['Predicted Sentiment'] = y_pred\n",
        "df_test.to_csv(\"results.csv\", index=False)\n",
        "print(\"Saved results to results.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-dD-QEbEwLg",
        "outputId": "7793e58e-44cf-4747-c9da-199b06351d68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.937\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.00      0.00      0.00        24\n",
            "     neutral       0.00      0.00      0.00        39\n",
            "    positive       0.94      1.00      0.97       937\n",
            "\n",
            "    accuracy                           0.94      1000\n",
            "   macro avg       0.31      0.33      0.32      1000\n",
            "weighted avg       0.88      0.94      0.91      1000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved results to results.csv\n"
          ]
        }
      ]
    }
  ]
}